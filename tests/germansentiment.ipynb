{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=False)\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "media = [\n",
    "    'junge Welt',\n",
    "    \"NachDenkSeiten\",\n",
    "    'taz',\n",
    "    'Süddeutsche Zeitung',\n",
    "    'stern TV',\n",
    "    \"DER SPIEGEL\",\n",
    "    'Der Tagesspiegel',\n",
    "    'ARD',\n",
    "    'tagesschau',\n",
    "    'ZDF',\n",
    "    \"ZDFheute Nachrichten\",\n",
    "    'Bayerischer Rundfunk',\n",
    "    'ntv Nachrichten',\n",
    "    'RTL',\n",
    "    'FOCUS Online',\n",
    "    'ZEIT ONLINE',\n",
    "    'faz',\n",
    "    'WELT',\n",
    "    \"BILD\",\n",
    "    'NZZ Neue Zürcher Zeitung',\n",
    "    \"Junge Freiheit\",\n",
    "    'COMPACTTV'\n",
    "]\n",
    "\n",
    "search_terms = {\n",
    "    'cdu':['cdu'],\n",
    "    'csu':['csu'],\n",
    "    'fdp':['fdp'],\n",
    "    'grüne':['grüne'],\n",
    "    'linke':['linke'],\n",
    "    'afd':['afd', 'afg'],\n",
    "    'spd':['spd'],\n",
    "}\n",
    "\n",
    "df = pd.read_pickle('../data/topic.pkl')\n",
    "df['contains_cdu'] = df['preprocessed'].str.contains('cdu')\n",
    "df['contains_csu'] = df['preprocessed'].str.contains('csu')\n",
    "df['contains_fdp'] = df['preprocessed'].str.contains('fdp')\n",
    "df['contains_grüne'] = df['preprocessed'].str.contains('grüne') \n",
    "df['contains_linke'] = df['preprocessed'].str.contains('linke')\n",
    "df['contains_afd'] = df['preprocessed'].str.contains('afd') | df['preprocessed'].str.contains('afg')\n",
    "df['contains_spd'] = df['preprocessed'].str.contains('spd')\n",
    "\n",
    "def extract_party_mentions(input_string, party_strings, n_words=10):\n",
    "    party_boolean = [False for i in input_string.split()]\n",
    "    for p in party_strings:\n",
    "        temp = [string.__contains__(p) for string in input_string.split()]\n",
    "        party_boolean = [party_boolean|temp for (party_boolean,temp) in zip(party_boolean, temp)]\n",
    "    party_index = np.where(party_boolean)[0]\n",
    "    return [\" \".join(input_string.split()[party_index[i]-n_words:party_index[i]+(n_words+1)]) for i in range(len(party_index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'negative', 'score': 0.988132655620575}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mdraw/german-news-sentiment-bert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"mdraw/german-news-sentiment-bert\")\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "classifier(\"Dies ist ein schlechter Test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strings: ['mal einen großen streit tag bei future nun sind die grünen in der bundesregierung wenn es nach der ampel geht soll', 'wie zu erwarten war aus viele jugendliche sehen in den grünen jedoch ein fortschritt wie geht']\n",
      "Classification: [{'label': 'negative', 'score': 0.670270562171936}, {'label': 'neutral', 'score': 0.46254244446754456}]\n"
     ]
    }
   ],
   "source": [
    "ind = 4\n",
    "party = 'grüne'\n",
    "\n",
    "subset = 'contains_' + party\n",
    "teststring = df.loc[df[subset]].iloc[ind]['transcript']\n",
    "extracted_strings = extract_party_mentions(input_string=teststring, party_strings=search_terms[party])\n",
    "print(f'Strings: {extracted_strings}')\n",
    "print(f'Classification: {classifier(extracted_strings)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mention_df(party):\n",
    "    subset = 'contains_' + party\n",
    "    res_series = df['transcript'].loc[df[subset]].parallel_apply(lambda transcript: extract_party_mentions(input_string=transcript, party_strings=search_terms[party], n_words=10))\n",
    "    temp = {'medium': df['medium'].loc[df[subset]], 'transcript':res_series}\n",
    "    res_df = pd.DataFrame(temp).explode(column='transcript')\n",
    "    res_df.reset_index(inplace=True)\n",
    "    res_df.dropna(inplace=True)\n",
    "    res_df.drop(res_df.index[res_df['transcript'] == ''], inplace=True)\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentiment_df(input_df):\n",
    "    input_df['sentiment'] = input_df['transcript'].progress_apply(classifier)\n",
    "    input_df['positive'] = [True if sent[0]['label']=='positive' else False for sent in input_df['sentiment']]\n",
    "    input_df['neutral'] = [True if sent[0]['label']=='neutral' else False for sent in input_df['sentiment']]\n",
    "    input_df['negative'] = [True if sent[0]['label']=='negative' else False for sent in input_df['sentiment']]\n",
    "    input_df['score'] = [sent[0]['score'] for sent in input_df['sentiment']]\n",
    "    return input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_avg_sentiment_df(input_df):\n",
    "    avg_pos = input_df[input_df['positive']].groupby(['medium'])['score'].mean()\n",
    "    avg_neu = input_df[input_df['neutral']].groupby(['medium'])['score'].mean()\n",
    "    avg_neg = input_df[input_df['negative']].groupby(['medium'])['score'].mean()\n",
    "    output_df = pd.DataFrame(data={'avg_pos':avg_pos, 'avg_neu':avg_neu, 'avg_neg':avg_neg})\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_party_sentiment(party):\n",
    "    df = extract_mention_df(party)\n",
    "    df = extract_sentiment_df(df)\n",
    "    df = extract_avg_sentiment_df(df)\n",
    "    avg = df['avg_pos'] - df['avg_neg']\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33238/33238 [35:37<00:00, 15.55it/s] \n",
      "100%|██████████| 11875/11875 [12:47<00:00, 15.48it/s]\n",
      "100%|██████████| 21404/21404 [20:38<00:00, 17.28it/s]\n",
      "100%|██████████| 37298/37298 [36:34<00:00, 17.00it/s]\n",
      "100%|██████████| 17777/17777 [16:52<00:00, 17.55it/s] \n",
      "100%|██████████| 25391/25391 [25:29<00:00, 16.60it/s]\n",
      "100%|██████████| 33166/33166 [36:24<00:00, 15.18it/s]  \n"
     ]
    }
   ],
   "source": [
    "sentiment_dict = {}\n",
    "for party in search_terms.keys():\n",
    "    sentiment_dict[party] = get_avg_party_sentiment(party)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ae7ae13804f56b6812076ff88d4c743516b7c995d69dd5984882be015e04ad2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
