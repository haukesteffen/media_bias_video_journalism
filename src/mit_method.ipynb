{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_warnings = True\n",
    "if ignore_warnings:\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "political_spectrum_dict = {\n",
    "    'junge Welt':'left',\n",
    "    'NachDenkSeiten':'left',\n",
    "    'taz':'left leaning',\n",
    "    'Süddeutsche Zeitung':'left leaning',\n",
    "    'stern TV':'left leaning',\n",
    "    'DER SPIEGEL':'left leaning',\n",
    "    'Der Tagesspiegel':'center',\n",
    "    'ARD':'center',\n",
    "    'ZDF':'center',\n",
    "    'ZDFheute Nachrichten':'center',\n",
    "    'Bayerischer Rundfunk':'center',\n",
    "    'ntv Nachrichten':'center',\n",
    "    'RTL':'right leaning',\n",
    "    'FOCUS Online':'right leaning',\n",
    "    'ZEIT ONLINE':'left leaning',\n",
    "    'faz':'right leaning',\n",
    "    'WELT':'right leaning',\n",
    "    'BILD':'right leaning',\n",
    "    'NZZ Neue Zürcher Zeitung':'right leaning',\n",
    "    'Junge Freiheit':'right',\n",
    "    'COMPACTTV':'right',\n",
    "}\n",
    "\n",
    "media = [\n",
    "    'junge Welt',\n",
    "    \"NachDenkSeiten\",\n",
    "    'taz',\n",
    "    'Süddeutsche Zeitung',\n",
    "    'stern TV',\n",
    "    \"DER SPIEGEL\",\n",
    "    'Der Tagesspiegel',\n",
    "    'ARD',\n",
    "    'Tagesschau',\n",
    "    'ZDF',\n",
    "    \"ZDFheute Nachrichten\",\n",
    "    'Bayerischer Rundfunk',\n",
    "    'ntv Nachrichten',\n",
    "    'RTL',\n",
    "    'FOCUS Online',\n",
    "    'ZEIT ONLINE',\n",
    "    'faz',\n",
    "    'WELT',\n",
    "    \"BILD\",\n",
    "    'NZZ Neue Zürcher Zeitung',\n",
    "    \"Junge Freiheit\",\n",
    "    'COMPACTTV'\n",
    "]\n",
    "\n",
    "def define_print(verbose=True):\n",
    "    if verbose:\n",
    "        verboseprint = print\n",
    "    else:\n",
    "        verboseprint = lambda *args: None\n",
    "    return verboseprint\n",
    "\n",
    "def get_N_matrix(df, verbose=True, drop_subsumed=True, drop_medium_specific=True):\n",
    "    verboseprint = define_print(verbose=verbose)\n",
    "    MEDIA = media\n",
    "    cv = CountVectorizer(max_df=0.9, min_df=10, max_features=10000, ngram_range=(1, 3))\n",
    "    topic = df.iloc[0]['topic']\n",
    "    \n",
    "    verboseprint(\"restructuring dataframe with \" + str(len(df)) + \" transcripts...\")\n",
    "    df[\"preprocessed\"] = df[\"preprocessed\"] + \" \"\n",
    "    df = df[[\"medium\", \"preprocessed\", \"topic\"]]\n",
    "    df_grouped = df.groupby([\"medium\", \"topic\"]).sum()\n",
    "\n",
    "    df = pd.DataFrame(index=MEDIA, columns=[\"preprocessed\"])\n",
    "    empty_media = []\n",
    "    for medium in MEDIA:\n",
    "        try:\n",
    "            df.loc[medium] = df_grouped.loc[medium].loc[topic][\"preprocessed\"]\n",
    "        except:\n",
    "            print(\n",
    "                medium\n",
    "                + \" does not have any videos categorized under category '\"\n",
    "                + topic\n",
    "                + \"'.\"\n",
    "            )\n",
    "            df.drop(index=medium, inplace=True)\n",
    "            empty_media.append(medium)\n",
    "\n",
    "    for empty_medium in empty_media:\n",
    "        MEDIA.remove(empty_medium)\n",
    "\n",
    "    verboseprint(\"fitting cv model for topic \" + topic + \"...\")\n",
    "    N_matrix = cv.fit_transform(df[\"preprocessed\"].values)\n",
    "\n",
    "    verboseprint(\"counting n-gram occurences...\")\n",
    "    N_df = pd.DataFrame(\n",
    "        data=N_matrix.toarray().transpose(),\n",
    "        columns=df.index,\n",
    "        index=cv.get_feature_names_out(),\n",
    "    )\n",
    "\n",
    "    if drop_medium_specific:\n",
    "        verboseprint(\n",
    "            \"dropping medium-specific n-grams that occur in one medium at least 90% of the time...\"\n",
    "        )\n",
    "        N_sum = N_df.sum(axis=1)\n",
    "        specific_mask = np.full(len(N_df.index), False)\n",
    "        mask_df = N_df.apply(lambda x: x>0.9*N_sum)\n",
    "        for medium in MEDIA:\n",
    "            specific_mask = specific_mask | mask_df[medium].values\n",
    "        N_df.drop(N_df.index[specific_mask], inplace=True)\n",
    "\n",
    "    if drop_subsumed:\n",
    "        N_df = N_df.reset_index().rename(columns={\"index\": \"phrase\"})\n",
    "        N_df[\"n_gram\"] = N_df[\"phrase\"].apply(str.split).apply(len)\n",
    "        N_df[\"count\"] = N_df[MEDIA].sum(axis=1)\n",
    "\n",
    "        monograms = N_df[N_df[\"n_gram\"] == 1]\n",
    "        bigrams = N_df[N_df[\"n_gram\"] == 2]\n",
    "        trigrams = N_df[N_df[\"n_gram\"] == 3]\n",
    "        bigram_words = list(\n",
    "            set(\n",
    "                [\n",
    "                    word\n",
    "                    for bigram_sublist in bigrams[\"phrase\"].apply(str.split).tolist()\n",
    "                    for word in bigram_sublist\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        trigram_words = list(\n",
    "            set(\n",
    "                [\n",
    "                    word\n",
    "                    for trigram_sublist in trigrams[\"phrase\"].apply(str.split).tolist()\n",
    "                    for word in trigram_sublist\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        verboseprint(\"extracting subsumed n-grams...\")\n",
    "        monograms_in_bigrams = monograms[monograms[\"phrase\"].isin(bigram_words)]\n",
    "        monograms_in_trigrams = monograms[monograms[\"phrase\"].isin(trigram_words)]\n",
    "\n",
    "        bigrams_in_trigrams_words = list(\n",
    "            set(\n",
    "                [\n",
    "                    bigram_word\n",
    "                    for bigram_word in bigram_words\n",
    "                    if bigram_word in trigram_words\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        bigrams_in_trigrams_mask = bigrams[\"phrase\"].apply(\n",
    "            lambda bigram: True\n",
    "            if bigram.split()[0] in bigrams_in_trigrams_words\n",
    "            or bigram.split()[1] in bigrams_in_trigrams_words\n",
    "            else False\n",
    "        )\n",
    "        bigrams_in_trigrams = bigrams[bigrams_in_trigrams_mask]\n",
    "\n",
    "        threshold = 0.7\n",
    "        verboseprint(\n",
    "            f\"filtering n-grams which are subsumed more than {int(100*threshold)}% of the time...\"\n",
    "        )\n",
    "        monograms_in_bigrams_above_threshold = list(\n",
    "            set(\n",
    "                [\n",
    "                    monogram[\"phrase\"]\n",
    "                    for _, monogram in monograms_in_bigrams.iterrows()\n",
    "                    for _, bigram in bigrams.iterrows()\n",
    "                    if monogram[\"phrase\"] in bigram[\"phrase\"].split()\n",
    "                    and bigram[\"count\"] > threshold * monogram[\"count\"]\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        monograms_in_trigrams_above_threshold = list(\n",
    "            set(\n",
    "                [\n",
    "                    monogram[\"phrase\"]\n",
    "                    for _, monogram in monograms_in_trigrams.iterrows()\n",
    "                    for _, trigram in trigrams.iterrows()\n",
    "                    if monogram[\"phrase\"] in trigram[\"phrase\"].split()\n",
    "                    and trigram[\"count\"] > threshold * monogram[\"count\"]\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        bigrams_in_trigrams_above_threshold = list(\n",
    "            set(\n",
    "                [\n",
    "                    bigram[\"phrase\"]\n",
    "                    for _, bigram in bigrams_in_trigrams.iterrows()\n",
    "                    for _, trigram in trigrams.iterrows()\n",
    "                    if (\n",
    "                        bigram[\"phrase\"] in \" \".join(trigram[\"phrase\"].split()[:2])\n",
    "                        or bigram[\"phrase\"] in \" \".join(trigram[\"phrase\"].split()[-2:])\n",
    "                    )\n",
    "                    and trigram[\"count\"] > threshold * bigram[\"count\"]\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        n_grams_above_threshold = list(\n",
    "            set(\n",
    "                np.append(\n",
    "                    np.append(\n",
    "                        monograms_in_bigrams_above_threshold,\n",
    "                        monograms_in_trigrams_above_threshold,\n",
    "                    ),\n",
    "                    bigrams_in_trigrams_above_threshold,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        N_df.drop(\n",
    "            N_df[N_df[\"phrase\"].isin(n_grams_above_threshold)].index, inplace=True\n",
    "        )\n",
    "        N_df.set_index(\"phrase\", inplace=True)\n",
    "        N_df.drop(columns=[\"n_gram\", \"count\"], inplace=True)\n",
    "    return N_df\n",
    "\n",
    "def filter_N_by_information_score(N_df, n=1000, verbose=True):\n",
    "    verboseprint = define_print(verbose=verbose)\n",
    "    verboseprint(\"filtering \" + str(n) + \" most discriminative phrases from sample...\")\n",
    "    n_i = len(N_df.index)\n",
    "    n_j = len(N_df.columns)\n",
    "    P_ij = N_df / N_df.to_numpy().sum()\n",
    "    P_i = P_ij.sum(axis=1)\n",
    "    P_j = P_ij.sum(axis=0)\n",
    "\n",
    "    I = np.zeros((n_i, n_j))\n",
    "\n",
    "    for i in range(n_i):\n",
    "        for j in range(n_j):\n",
    "            I[i][j] = P_ij.values[i][j] * np.log2(P_ij.values[i][j] / P_i[i] / P_j[j])\n",
    "\n",
    "    I = pd.DataFrame(I, index=N_df.index, columns=N_df.columns)\n",
    "    I = I.fillna(0.0)\n",
    "    I[\"sum\"] = I.sum(axis=1)\n",
    "    I.sort_values(by=\"sum\", ascending=False, inplace=True)\n",
    "    return N_df.loc[I.index[:n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/topics_combined.pkl')\n",
    "topic_counts = df['topic'].value_counts()\n",
    "topic_dict = dict(zip(np.arange(-1,89), topic_counts.index.to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whitelist = {}\n",
    "for i in range(-1,89):\n",
    "    whitelist[i] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whitelist[7] = [\n",
    "    'polen',\n",
    "    'ukrainischen',\n",
    "    'ukrainische',\n",
    "    'geflüchtete',\n",
    "    'migranten',\n",
    "    'kiew',\n",
    "    'russischen',\n",
    "    'libyen',\n",
    "    'bahnhof',\n",
    "    'asylbewerber',\n",
    "    'menschen ukraine',\n",
    "    'zug',\n",
    "    'helfen',\n",
    "    'lampedusa',\n",
    "    'polnischen',\n",
    "    'ukrainischen grenze',\n",
    "    'ukrainer',\n",
    "    'russland',\n",
    "    'migrations',\n",
    "    'krieges',\n",
    "    'serbien',\n",
    "    'spenden',\n",
    "    'kindern',\n",
    "    'verteilung',\n",
    "    'einwanderung',\n",
    "    'schiff',\n",
    "    'polnisch',\n",
    "    'russische',\n",
    "    'unterstützung',\n",
    "    'zuwanderung',\n",
    "    'küstenwache',\n",
    "    'hilfsbereitschaft',\n",
    "    'balkanroute',\n",
    "    'westen',\n",
    "    'frauen kinder',\n",
    "    'mittelmeer',\n",
    "    'migrationshintergrund',\n",
    "    'hafen',\n",
    "    'boot',\n",
    "    'fliehen',\n",
    "    'einwanderer',\n",
    "    'österreich',\n",
    "    'camp',\n",
    "    'nachbarländer',\n",
    "    'mazedonien',\n",
    "    'belarus',\n",
    "    'kosovo',\n",
    "    'ausländer',\n",
    "    'kriegsflüchtlinge',\n",
    "    'eritrea',\n",
    "    'geflohen',\n",
    "    'illegal',\n",
    "    'kroatien',\n",
    "    'polnischen grenze',\n",
    "    'afrika',\n",
    "    'flucht',\n",
    "    'bomben',\n",
    "    'grenzübergang',\n",
    "    'ukrainerinnen',\n",
    "    'libysche',\n",
    "    'masseneinwanderung',\n",
    "    'ukrainisch',\n",
    "    'libyschen',\n",
    "    'abgeschoben',\n",
    "    'albanien',\n",
    "    'polnische',\n",
    "    'moria',\n",
    "    'warschau',\n",
    "    'schlepper',\n",
    "    'inseln',\n",
    "    'migrantinnen',\n",
    "    'unterbringung',\n",
    "    'krise',\n",
    "    'bosnien',\n",
    "    'griechischen',\n",
    "    'verteilt',\n",
    "    'fluchtursachen',\n",
    "    'willkommenskultur',\n",
    "    'slowakei',\n",
    "    'überfahrt',\n",
    "    'illegale',\n",
    "    'ukrainischer',\n",
    "    'unterstützen',\n",
    "    'obergrenze',\n",
    "    'deutschen',\n",
    "    'seenot',\n",
    "    'einwanderungsgesetz',\n",
    "    'arbeit',\n",
    "    'schweiz',\n",
    "    'männer',\n",
    "    'verteilen',\n",
    "    'russen',\n",
    "    'küste',\n",
    "    'freiwillige',\n",
    "    'land verlassen',\n",
    "    'zaun',\n",
    "    'zivilisten',\n",
    "    'ehrenamtliche',\n",
    "    'arbeiter',\n",
    "    'flüchtlingskrise',\n",
    "    'afrikaner',\n",
    "    'illegalen',\n",
    "    'rumänien',\n",
    "    'lesbos',\n",
    "    'marokko',\n",
    "    'ankunft',\n",
    "    'balkan',\n",
    "    'boote',\n",
    "    'kriegsflüchtlingen',\n",
    "    'sicherheit',\n",
    "    'schiffe',\n",
    "    'bürger',\n",
    "    'kind',\n",
    "    'schweizer',\n",
    "    'verwandten',\n",
    "    'flüchtling',\n",
    "    'einwanderungs',\n",
    "    'flüchten',\n",
    "    'ukrainerin',\n",
    "    'aufzunehmen',\n",
    "    'malta',\n",
    "    'rassismus',\n",
    "    'weißrussland',\n",
    "    'familien',\n",
    "    'aufnehmen',\n",
    "    'reduzieren',\n",
    "    'abwanderung',\n",
    "    'ukraine krieg',\n",
    "    'solidarität',\n",
    "    'syrer',\n",
    "    'armut',\n",
    "    'lebensmittel',\n",
    "    'ursachen',\n",
    "    'fachkräfte',\n",
    "    'asylrecht',\n",
    "    'afghanen',\n",
    "    'verfahren',\n",
    "    'schlauchboot',\n",
    "    'asylverfahren',\n",
    "    'asylpolitik',\n",
    "    'menschenrechte',\n",
    "    'spanien',\n",
    "    'mütter',\n",
    "    'integration',\n",
    "    'frieden',\n",
    "    'grundgesetz',\n",
    "    'frontex',\n",
    "    'abschiebung',\n",
    "    'kriege',\n",
    "    'opfer',\n",
    "    'flüchtlings',\n",
    "    'duldung',\n",
    "    'platz',\n",
    "    'gruppen',\n",
    "    'ukraine geflohen',\n",
    "    'ausbeutung',\n",
    "    'zuflucht',\n",
    "    'sozialstaat',\n",
    "    'afghanistan',\n",
    "    'bundesinnenministerium',\n",
    "    'gerettet',\n",
    "    'familiennachzug',\n",
    "    'ungarn',\n",
    "    'irak',\n",
    "    'zurückgeschickt',\n",
    "    'bulgarien',\n",
    "    'arbeitsmarkt',\n",
    "    'griechen',\n",
    "    'nachbarland',\n",
    "    'wohnung',\n",
    "    'hilfsorganisationen',\n",
    "    'tunesien',\n",
    "    'einwanderungsland',\n",
    "    'lagern',\n",
    "    'herkunft',\n",
    "    'nigeria',\n",
    "    'einwanderungspolitik',\n",
    "    'flüchtlingskonvention',\n",
    "    'europäische union',\n",
    "    'seenotrettung',\n",
    "    'griechischen inseln',\n",
    "    'unterkunft',\n",
    "    'asylsuchende',\n",
    "    'hilfsgüter',\n",
    "    'vergewaltigt',\n",
    "    'bürgerkrieg',\n",
    "    'abschiebungen',\n",
    "    'kroatischen',\n",
    "    'europäischen union',\n",
    "    'zurückkehren',\n",
    "    'kriminalität',\n",
    "    'wirtschaftsflüchtlinge',\n",
    "    'geflüchtet',\n",
    "    'flüchtlingslagern',\n",
    "    'flüchtlinge aufgenommen',\n",
    "    'asylrechts',\n",
    "    'asylbewerbern',\n",
    "    'neuankömmlinge',\n",
    "    'ertrinken',\n",
    "    'kultur',\n",
    "    'eu staaten',\n",
    "    'ausländern',\n",
    "    'asylantrag',\n",
    "    'immigranten',\n",
    "    'flüchtenden',\n",
    "    'flüchtlingslager',\n",
    "    'außengrenzen',\n",
    "    'litauen',\n",
    "    'zuwanderer',\n",
    "    'visa',\n",
    "    'mitgliedstaaten',\n",
    "    'flüchtende',\n",
    "    'überqueren',\n",
    "    'hilfsorganisation',\n",
    "    'illegaler',\n",
    "    'flüchtlingsstrom',\n",
    "    'festland',\n",
    "    'meer',\n",
    "    'unterkünfte',\n",
    "    'einwanderern',\n",
    "    'europäische länder',\n",
    "    'grenzpolizei',\n",
    "    'nato',\n",
    "    'zurückgebracht',\n",
    "    'medizinische versorgung',\n",
    "    'widerstand',\n",
    "    'flüchtlingsheim',\n",
    "    'zelte',\n",
    "    'staatsbürgerschaft',\n",
    "    'arbeitskräfte',\n",
    "    'leistungen',\n",
    "    'bekämpfung',\n",
    "    'migrationspolitik',\n",
    "    'rückkehr',\n",
    "    'verfolgung',\n",
    "    'schleppern',\n",
    "    'humanitäre',\n",
    "    'bezahlen',\n",
    "    'täter',\n",
    "    'menschen migrationshintergrund',\n",
    "    'proteste',\n",
    "    'insel lesbos',\n",
    "    'millionen flüchtlinge',\n",
    "    'asylanträge',\n",
    "    'syrischen',\n",
    "    'illegale migration',\n",
    "    'verwandte',\n",
    "    'rechtsstaat',\n",
    "    'container',\n",
    "    'migrant',\n",
    "    'slowenien',\n",
    "    'angriffskrieg',\n",
    "    'empfangen',\n",
    "    'schleuser',\n",
    "    'kontrollieren',\n",
    "    'illegale einwanderer',\n",
    "    'griechischen insel',\n",
    "    'asylsuchenden',\n",
    "    'rechtsradikalen',\n",
    "    'grenzschützer',\n",
    "    'überfüllt',\n",
    "    'traumatisiert',\n",
    "    'flüchtlingsunterkunft',\n",
    "    'verfolgt',\n",
    "    'demonstrationen',\n",
    "    'grenzöffnung',\n",
    "    'grenzregion',\n",
    "    'flüchtlingscamp',\n",
    "    'somalia',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whitelist[10] = [\n",
    "    'windräder',\n",
    "    'ausbau',\n",
    "    'solar',\n",
    "    'energiewende',\n",
    "    'wetter',\n",
    "    'ausbau erneuerbaren energien',\n",
    "    'pflanzen',\n",
    "    'windrad',\n",
    "    'klimakatastrophe',\n",
    "    'klimabewegung',\n",
    "    'studie',\n",
    "    'climate',\n",
    "    'photovoltaik',\n",
    "    'wasserstoff',\n",
    "    'erwärmung',\n",
    "    'wissenschaftler',\n",
    "    'erderwärmung',\n",
    "    'kohlendioxid',\n",
    "    'wind',\n",
    "    'eeg',\n",
    "    'elektroauto',\n",
    "    'ökostrom',\n",
    "    'klimaneutralität',\n",
    "    'klimapolitik',\n",
    "    'tempolimit',\n",
    "    'klimadebatte',\n",
    "    'öko',\n",
    "    'infrastruktur',\n",
    "    'atmosphäre',\n",
    "    'heizung',\n",
    "    'nachhaltigkeit',\n",
    "    'treibhausgase',\n",
    "    'kohleausstieg',\n",
    "    'rwe',\n",
    "    'stromerzeugung',\n",
    "    'verkehr',\n",
    "    'energiepreise',\n",
    "    'solaranlage',\n",
    "    'windkraft',\n",
    "    'fleisch',\n",
    "    'gerechtigkeit',\n",
    "    'windpark',\n",
    "    'temperatur',\n",
    "    'kernenergie',\n",
    "    'offshore',\n",
    "    'windkraftanlagen',\n",
    "    'industrie',\n",
    "    'windenergie',\n",
    "    'energieversorgung',\n",
    "    'klimaziele',\n",
    "    'zertifikate',\n",
    "    'wasserkraft',\n",
    "    'klimapaket',\n",
    "    'umweltschutz',\n",
    "    'emissionshandel',\n",
    "    'weltklimarat',\n",
    "    'braunkohle',\n",
    "    'kernkraft',\n",
    "    'kraftwerke',\n",
    "    'klimaneutral',\n",
    "    'strompreis',\n",
    "    'solarzellen',\n",
    "    'photovoltaikanlagen',\n",
    "    'solaranlagen',\n",
    "    'technologie',\n",
    "    'windparks',\n",
    "    'fußabdruck',\n",
    "    'meeresspiegel',\n",
    "    'methan',\n",
    "    'fracking',\n",
    "    'erwärmt',\n",
    "    'kraftwerk',\n",
    "    'solarenergie',\n",
    "    'diesel',\n",
    "    'erneuerbare energien',\n",
    "    'folgen klimawandels',\n",
    "    'energiepolitik',\n",
    "    'pariser klimaabkommen',\n",
    "    'atomkraft',\n",
    "    'stromnetz',\n",
    "    'energieträger',\n",
    "    'klimaschutzgesetz',\n",
    "    'klimagipfel',\n",
    "    'klima thema',\n",
    "    'klima paket',\n",
    "    'klimaaktivisten',\n",
    "    'klimafreundlicher',\n",
    "    'erdgas',\n",
    "    'stromversorgung',\n",
    "    'grad celsius',\n",
    "    'kampf klimawandel',\n",
    "    'ausbau windenergie',\n",
    "    'biomasse',\n",
    "    'klimaschutzziele',\n",
    "    'klimafrage',\n",
    "    'treibhausgasen',\n",
    "    'naturschutz',\n",
    "    'strombedarf',\n",
    "    'atomkraftwerke',\n",
    "    'klimakonferenz',\n",
    "    'weltklimakonferenz',\n",
    "    'windstrom',\n",
    "    'eeg umlage',\n",
    "    'klimaziele erreichen',\n",
    "    'erneuerbarer energien',\n",
    "    'treibhausgas',\n",
    "    'erneuerbaren strom',\n",
    "    'klimaforscher',\n",
    "    'greta thunberg',\n",
    "    'erwärmung grad',\n",
    "    'fossilen energien',\n",
    "    'menschengemachten klimawandel',\n",
    "    'windrädern',\n",
    "    'geothermie',\n",
    "    'dekarbonisierung',\n",
    "    'sonnenenergie',\n",
    "    'strom produzieren',\n",
    "    'brennstoffe',\n",
    "    'kraftwerken',\n",
    "    'grad ziel',\n",
    "    'erderwärmung grad',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whitelist[3] = [\n",
    "    'täter',\n",
    "    'einsatz',\n",
    "    'urteil',\n",
    "    'anklage',\n",
    "    'antifa',\n",
    "    'nsu',\n",
    "    'protest',\n",
    "    'landgericht',\n",
    "    'verfassungsschutz',\n",
    "    'tatverdächtigen',\n",
    "    'strafbar',\n",
    "    'akten',\n",
    "    'leiche',\n",
    "    'staatsanwaltschaft',\n",
    "    'beamte',\n",
    "    'kundgebung',\n",
    "    'kapitol',\n",
    "    'bundesgerichtshof',\n",
    "    'ermittlungen',\n",
    "    'verurteilt',\n",
    "    'prozess',\n",
    "    'verletzt',\n",
    "    'geldstrafe',\n",
    "    'strafmaß',\n",
    "    'strafe',\n",
    "    'proteste',\n",
    "    'polizistinnen polizisten',\n",
    "    'einsatzkräfte',\n",
    "    'ermittler',\n",
    "    'anwälte',\n",
    "    'mörder',\n",
    "    'kinderpornografie',\n",
    "    'demonstrationen',\n",
    "    'demo',\n",
    "    'festgenommen',\n",
    "    'staatsanwälte',\n",
    "    'angeklagten',\n",
    "    'strafrecht',\n",
    "    'haft',\n",
    "    'missbrauch',\n",
    "    'unfall',\n",
    "    'rassismus',\n",
    "    'sexualisierter gewalt',\n",
    "    'strafverfahren',\n",
    "    'richterin',\n",
    "    'beschuldigten',\n",
    "    'verteidigung',\n",
    "    'zeugen',\n",
    "    'unschuldsvermutung',\n",
    "    'verteidiger',\n",
    "    'tatort',\n",
    "    'sexualisierte gewalt',\n",
    "    'motiv',\n",
    "    'verdächtige',\n",
    "    'waffen',\n",
    "    'bundespolizei',\n",
    "    'tatverdächtige',\n",
    "    'gegendemonstranten',\n",
    "    'drogen',\n",
    "    'messer',\n",
    "    'aktivisten',\n",
    "    'tatbestand',\n",
    "    'justiz',\n",
    "    'flucht',\n",
    "    'betroffenen',\n",
    "    'angaben polizei',\n",
    "    'straftaten',\n",
    "    'schüsse',\n",
    "    'bundesanwaltschaft',\n",
    "    'kriminell',\n",
    "    'todesstrafe',\n",
    "    'gerichtssaal',\n",
    "    'geschossen',\n",
    "    'dna',\n",
    "    'polizeibeamten',\n",
    "    'kindesmissbrauch',\n",
    "    'knast',\n",
    "    'widerstand',\n",
    "    'erschossen',\n",
    "    'querdenken',\n",
    "    'rechtsextremen',\n",
    "    'mord',\n",
    "    'waffe',\n",
    "    'berufung',\n",
    "    'staatsanwalt',\n",
    "    'amtsgericht',\n",
    "    'munition',\n",
    "    'verletzungen',\n",
    "    'querdenker',\n",
    "    'sicherheitsbehörden',\n",
    "    'berliner polizei',\n",
    "    'rechtsprechung',\n",
    "    'festnahme',\n",
    "    'protesten',\n",
    "    'rechtsextremismus',\n",
    "    'migranten',\n",
    "    'beihilfe',\n",
    "    'bewaffnet',\n",
    "    'angeklagt',\n",
    "    'verdächtigen',\n",
    "    'oberlandesgericht',\n",
    "    'bewährung',\n",
    "    'staatsanwaltschaften',\n",
    "    'demonstriert',\n",
    "    'angeklagte',\n",
    "    'paragraf',\n",
    "    'block',\n",
    "    'krimi',\n",
    "    'morde',\n",
    "    'schuld',\n",
    "    'betroffene',\n",
    "    'geheimdienst',\n",
    "    'durchsucht',\n",
    "    'jury',\n",
    "    'schuldig',\n",
    "    'rechtsextreme',\n",
    "    'ausschreitungen',\n",
    "    'straftat',\n",
    "    'polizeisprecher',\n",
    "    'demonstrieren',\n",
    "    'eskaliert',\n",
    "    'gutachten',\n",
    "    'haftstrafe',\n",
    "    'raub',\n",
    "    'mandanten',\n",
    "    'strafrechtlichen',\n",
    "    'freigesprochen',\n",
    "    'vorgeworfen',\n",
    "    'besitz',\n",
    "    'räumung',\n",
    "    'sexuelle gewalt',\n",
    "    'taten',\n",
    "    'spuren',\n",
    "    'verstöße',\n",
    "    'ermittelt',\n",
    "    'betrüger',\n",
    "    'hauptverhandlung',\n",
    "    'auflagen',\n",
    "    'attentat',\n",
    "    'haftbefehl',\n",
    "    'aussage',\n",
    "    'tot',\n",
    "    'straftatbestand',\n",
    "    'sichergestellt',\n",
    "    'polizistin',\n",
    "    'polizeibeamte',\n",
    "    'streifenwagen',\n",
    "    'dealer',\n",
    "    'juristisch',\n",
    "    'freiheitsstrafe',\n",
    "    'einsatzkräften',\n",
    "    'klage',\n",
    "    'unschuldig',\n",
    "    'leichen',\n",
    "    'mordes',\n",
    "    'vergewaltigung',\n",
    "    'angreifer',\n",
    "    'polizeigewalt',\n",
    "    'aufklärung',\n",
    "    'zugriff',\n",
    "    'korruption',\n",
    "    'kinderpornografische',\n",
    "    'asyl',\n",
    "    'sexueller gewalt',\n",
    "    'schuss',\n",
    "    'körperverletzung',\n",
    "    'sexuellen missbrauch',\n",
    "    'pistole',\n",
    "    'polizeiwache',\n",
    "    'verletzte',\n",
    "    'auseinandersetzungen',\n",
    "    'rechtskräftig',\n",
    "    'schwer verletzt',\n",
    "    'gerecht',\n",
    "    'tätern',\n",
    "    'mordfall',\n",
    "    'gerichte',\n",
    "    'neonazis',\n",
    "    'juristischen',\n",
    "    'bundeskriminalamt',\n",
    "    'protestieren',\n",
    "    'polizeigewerkschaft',\n",
    "    'polizisten einsatz',\n",
    "    'vorwurf',\n",
    "    'rassistische',\n",
    "    'verhandlung',\n",
    "    'eingestellt',\n",
    "    'polizeilichen',\n",
    "    'tötung',\n",
    "    'strafgesetzbuch',\n",
    "    'rechtsanwalt',\n",
    "    'hass',\n",
    "    'lka',\n",
    "    'spezialeinheiten',\n",
    "    'polizeiliche',\n",
    "    'zeuge',\n",
    "    'gewehr',\n",
    "    'töten',\n",
    "    'randalierer',\n",
    "    'untergrund',\n",
    "    'sexuellen missbrauchs',\n",
    "    'kriminalpolizei',\n",
    "    'verbrecher',\n",
    "    'missbraucht',\n",
    "    'getötet',\n",
    "    'überfall',\n",
    "    'missstände',\n",
    "    'verurteilung',\n",
    "    'angegriffen',\n",
    "    'schwarze',\n",
    "    'berufen',\n",
    "    'beschuldigte',\n",
    "    'spurensicherung',\n",
    "    'festnehmen',\n",
    "    'kriminalität',\n",
    "    'gestanden',\n",
    "    'wasserwerfer',\n",
    "    'mutmaßliche täter',\n",
    "    'polizei einsatz',\n",
    "    'ermordet',\n",
    "    'ermittlungsverfahren',\n",
    "    'festnahmen',\n",
    "    'zeugenaussage',\n",
    "    'anwältin',\n",
    "    'haftbefehle',\n",
    "    'gefasst',\n",
    "    'beweisen',\n",
    "    'schusswaffe',\n",
    "    'kontrolle'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_palette = [\n",
    "    'rgb(20.0, 20.0, 255.0)',\n",
    "    'rgb(50.0, 0.0, 170.0)',\n",
    "    'rgb(120.0, 120.0, 120.0)',\n",
    "    'rgb(170.0, 0.0, 50.0)',\n",
    "    'rgb(255.0, 20.0, 20.0)'\n",
    "]\n",
    "\n",
    "n_components=3\n",
    "scale = True\n",
    "plot = False\n",
    "\n",
    "def evaluate():\n",
    "    scaler = StandardScaler()\n",
    "    model = TruncatedSVD(n_components=n_components)\n",
    "\n",
    "    if scale:\n",
    "        N_scaled = scaler.fit_transform(N.values)\n",
    "        N_df_trunc = model.fit_transform(N_scaled)\n",
    "    else:\n",
    "        N_df_trunc = model.fit_transform(N.values)\n",
    "\n",
    "    export_df = pd.DataFrame(model.components_[1:], index=['X', 'Y'], columns=media)\n",
    "    export_df.to_pickle(f'../data/mit_method/{topic_dict[topic_index]}.pkl')\n",
    "\n",
    "    if plot:\n",
    "        for n in range(n_components):\n",
    "            fig = px.scatter(\n",
    "                x=model.components_[n], \n",
    "                y=[0.0 for test in model.components_[n]], \n",
    "                color=[political_spectrum_dict[medium] for medium in N.columns.to_list()],\n",
    "                color_discrete_sequence=color_palette,\n",
    "                hover_data=[N.columns.to_list()], \n",
    "                title=f'Topic: \\'{topic}\\', {n}. Principal Component',\n",
    "                )\n",
    "            fig.show()\n",
    "\n",
    "    n_phrases = 5\n",
    "    for axis in range(n_components):\n",
    "        ind_neg = np.argsort(N_df_trunc[:,axis])[:n_phrases]\n",
    "        ind_pos = np.argsort(N_df_trunc[:,axis])[-n_phrases:]\n",
    "        list_neg = N.index[ind_neg].to_list()\n",
    "        list_pos = N.index[ind_pos].to_list()\n",
    "        list_pos.reverse()\n",
    "        print(f'principal component: {axis}, most negative phrases: {list_neg}')\n",
    "        print(f'principal component: {axis}, most positive phrases: {list_pos}')\n",
    "\n",
    "    M = N.copy(deep=True)\n",
    "    M['dummy'] = np.round(M['NachDenkSeiten']).astype(int)\n",
    "    scaler_m = StandardScaler()\n",
    "    model_m = TruncatedSVD(n_components=n_components)\n",
    "\n",
    "    M_scaled = scaler_m.fit_transform(M.values)\n",
    "    M_df_trunc = model_m.fit_transform(M_scaled)\n",
    "\n",
    "    export_df_m = pd.DataFrame(model_m.components_[1:], index=['X', 'Y'], columns=media + ['dummy'])\n",
    "    export_df_m.to_pickle(f'../data/mit_method/{topic_dict[topic_index]}_unrobust.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic_index in [3,7,10]:\n",
    "    topic = topic_dict[topic_index]\n",
    "    print('topic: ' + topic)\n",
    "    N_df = get_N_matrix(df[df['topic'] == topic]) \n",
    "    N_df = filter_N_by_information_score(N_df, n=3000)\n",
    "    N = N_df[N_df.index.isin(whitelist[topic_index])]\n",
    "    print(f'words considered after filtering: {len(N.index)}')\n",
    "    evaluate()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ae7ae13804f56b6812076ff88d4c743516b7c995d69dd5984882be015e04ad2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
