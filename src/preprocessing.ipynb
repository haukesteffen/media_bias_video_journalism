{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtubesearchpython import Playlist, Channel, Video, playlist_from_channel_id\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "from pandarallel import pandarallel\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def define_print(verbose=True):\n",
    "    if verbose:\n",
    "        verboseprint = print\n",
    "    else:\n",
    "        verboseprint = lambda *args: None\n",
    "    return verboseprint\n",
    "\n",
    "def load_filter():\n",
    "    nlp = spacy.load(\"de_core_news_sm\")\n",
    "    filterwords = spacy.lang.de.stop_words.STOP_WORDS\n",
    "    with open(\"../assets/filterwords.txt\", encoding=\"utf-8\", errors=\"ignore\") as d:\n",
    "        filterwords.update(d.read().split())\n",
    "    with open(\"../assets/german_stopwords_full.txt\", encoding=\"utf-8\", errors=\"ignore\") as d:\n",
    "        filterwords.update(d.read().split()[53:])\n",
    "    return list(set(filterwords))\n",
    "\n",
    "def lemmatize(text, nlp, filterwords):\n",
    "    \"\"\"\n",
    "    tokenizes and lemmatizes german input text\n",
    "    :param text: raw input text (german)\n",
    "    :return: list of lemmatized tokens from input text\n",
    "    \"\"\"\n",
    "\n",
    "    with nlp.select_pipes(enable=\"lemmatizer\"):\n",
    "        doc = nlp(text)\n",
    "    lemmas = [token.lemma_.lower() for token in doc]\n",
    "    lemmas = [lemma for lemma in lemmas if lemma.isalpha() and lemma not in filterwords]\n",
    "    return \" \".join(lemmas)\n",
    "\n",
    "def preprocess(df, to_csv=False, to_pickle=False, verbose=True):\n",
    "    verboseprint = define_print(verbose=verbose)\n",
    "    pandarallel.initialize(progress_bar=True)\n",
    "    filterwords = load_filter()\n",
    "    nlp = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "    verboseprint(f\"lemmatizing transcript data of {len(df.index)} videos...\")\n",
    "    df[\"preprocessed\"] = df[\"transcript\"].parallel_apply(\n",
    "        lemmatize, args=(nlp, filterwords)\n",
    "    )\n",
    "\n",
    "    if to_csv:\n",
    "        df.to_csv(\"data/preprocessed/\" + df.iloc[0][\"medium\"] + \"_preprocessed.csv\")\n",
    "\n",
    "    if to_pickle:\n",
    "        df.to_pickle(\"data/preprocessed/\" + df.iloc[0][\"medium\"] + \"_preprocessed.pkl\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_pickle('../data/data.pkl')\n",
    "preprocessed_df = preprocess(data_df)\n",
    "preprocessed_df.to_pickle('../data/preprocessed.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ae7ae13804f56b6812076ff88d4c743516b7c995d69dd5984882be015e04ad2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
