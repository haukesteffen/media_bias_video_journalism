{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from bertopic import BERTopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import spacy\n",
    "\n",
    "media = [\n",
    "    'junge Welt',\n",
    "    \"NachDenkSeiten\",\n",
    "    'taz',\n",
    "    'Süddeutsche Zeitung',\n",
    "    'stern TV',\n",
    "    \"DER SPIEGEL\",\n",
    "    'Der Tagesspiegel',\n",
    "    'ARD',\n",
    "    'Tagesschau',\n",
    "    'ZDF',\n",
    "    \"ZDFheute Nachrichten\",\n",
    "    'Bayerischer Rundfunk',\n",
    "    'ntv Nachrichten',\n",
    "    'RTL',\n",
    "    'FOCUS Online',\n",
    "    'ZEIT ONLINE',\n",
    "    'faz',\n",
    "    'WELT',\n",
    "    \"BILD\",\n",
    "    'NZZ Neue Zürcher Zeitung',\n",
    "    \"Junge Freiheit\",\n",
    "    'COMPACTTV'\n",
    "]\n",
    "\n",
    "def load_filter():\n",
    "    nlp = spacy.load(\"de_core_news_sm\")\n",
    "    filterwords = spacy.lang.de.stop_words.STOP_WORDS\n",
    "    with open(\"../docs/filterwords.txt\", encoding=\"utf-8\", errors=\"ignore\") as d:\n",
    "        filterwords.update(d.read().split())\n",
    "    with open(\"../docs/german_stopwords_full.txt\", encoding=\"utf-8\", errors=\"ignore\") as d:\n",
    "        filterwords.update(d.read().split()[53:])\n",
    "    return list(set(filterwords))\n",
    "\n",
    "stop_words = frozenset(load_filter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/combined.pkl')\n",
    "df.dropna(subset=['transcript'], inplace=True)\n",
    "docs = df['transcript'].astype(str).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_model = CountVectorizer(stop_words=stop_words, ngram_range=(1,1))\n",
    "topic_model = BERTopic(vectorizer_model = vectorizer_model, verbose=1, language='multilingual', min_topic_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics, probs = topic_model.fit_transform(docs)\n",
    "topic_model.save('bertopic_model_combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = BERTopic.load('bertopic_model_combined')\n",
    "#topics, probs = topic_model.transform(docs)\n",
    "#topics = df['topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_barchart(topics=[3, 7, 10], n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_info = topic_model.get_topic_info()\n",
    "topic_dict = pd.Series(topic_info.Name.values,index=topic_info.Topic).to_dict()\n",
    "df['topic'] = topics\n",
    "df['topic'] = df['topic'].apply(lambda row: topic_dict[row])\n",
    "df['topic_prob'] = probs\n",
    "#df.to_pickle('../data/topics_by_minute/topics_by_minute_bertopic.pkl')\n",
    "#df.to_pickle('../data/topics_combined.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_hierarchy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_counts = df['topic'].value_counts()\n",
    "reverse_topic_dict = dict(zip(topic_counts.index.to_list(), np.arange(-1,89)))\n",
    "topic_dict = dict(zip(np.arange(-1,89), topic_counts.index.to_list()))\n",
    "df['topic_number'] = df['topic'].apply(lambda x: reverse_topic_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_per_class = topic_model.topics_per_class(\n",
    "    docs=df['transcript'].astype(str).to_numpy(), \n",
    "    topics=df['topic_number'].to_numpy(), \n",
    "    classes=df['medium'].to_numpy(),\n",
    ")\n",
    "frequency_dict = topics_per_class.groupby('Class')['Frequency'].sum().to_dict()\n",
    "topics_per_class['N'] = topics_per_class['Class'].apply(lambda x: frequency_dict[x])\n",
    "topics_per_class['Frequency'] = topics_per_class['Frequency']/topics_per_class['N']*100.0\n",
    "topics_per_class.drop(columns=['N'], inplace=True)\n",
    "sorted_df = pd.DataFrame()\n",
    "for medium in media:\n",
    "    temp_df = topics_per_class[topics_per_class['Class'] == medium]\n",
    "    sorted_df = pd.concat([sorted_df, temp_df], axis=0)\n",
    "topics_per_class = sorted_df\n",
    "topic_model.visualize_topics_per_class(topics_per_class)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ae7ae13804f56b6812076ff88d4c743516b7c995d69dd5984882be015e04ad2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
