{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt = pd.read_pickle('../assets/bundestag.pkl')\n",
    "bt.drop(columns=['Geburts-jahr', 'Land', 'Listen-platz', 'Erst-stimmen-anteil', 'Listen-platz', 'Wahlkreis', 'BeruflicherHintergrund', 'MdBseit', 'Bemerkungen'], inplace=True)\n",
    "party_blacklist = [\n",
    "    'fraktionslos(SSW)',\n",
    "    'fraktionslos (Zentrum)',\n",
    "    'fraktionslos (AfD)',\n",
    "    'fraktionslos (ehemals AfD)',\n",
    "]\n",
    "bt = bt[bt['Fraktion(Partei)'].isin(party_blacklist) == False]\n",
    "bt.loc[bt['Fraktion(Partei)'] == 'CDU/CSU (CDU)', 'Fraktion(Partei)'] = 'cdu'\n",
    "bt.loc[bt['Fraktion(Partei)'] == 'CDU/CSU (CSU)', 'Fraktion(Partei)'] = 'csu'\n",
    "politician_dict = bt.set_index('Name').to_dict()['Fraktion(Partei)']\n",
    "politicians = {\n",
    "    politician.lower():politician_dict[politician].lower() for politician in list(politician_dict.keys())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_terms = {'die linke':'linke',\n",
    "                'linkspartei':'linke',\n",
    "                'die grünen':'grüne',\n",
    "                'spd':'spd',\n",
    "                'freien demokraten':'fdp',\n",
    "                'fdp':'fdp',\n",
    "                'cdu':'cdu',\n",
    "                'csu':'csu',\n",
    "                'alternative für deutschland':'afd',\n",
    "                'afd':'afd', \n",
    "                'afg':'afd'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data, merge zdf, drop irrelevant media\n",
    "media_to_consider = ['NachDenkSeiten', 'taz', 'DER SPIEGEL', 'ARD', 'ZDF', 'Bayerischer Rundfunk', 'ntv Nachrichten', 'faz', 'WELT', 'BILD', 'COMPACTTV']\n",
    "df = pd.read_pickle('../data/combined.pkl')\n",
    "df.loc[df['medium'] == 'ZDFinfo Dokus & Reportagen', 'medium'] = 'ZDF'\n",
    "df.loc[df['medium'] == 'ZDFheute Nachrichten', 'medium'] = 'ZDF'\n",
    "df = df[df['medium'].isin(media_to_consider)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mention_df = pd.DataFrame(columns=['medium', 'id', 'title', 'minute', 'transcript', 'search_term', 'extracted_string'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_string(transcript, search_term):\n",
    "  # Use a regular expression to find all occurrences of the search term in the transcript\n",
    "  pattern = r\"(?i)\\b\" + re.escape(search_term) + r\"\\b\"\n",
    "  matches = re.finditer(pattern, transcript)\n",
    "\n",
    "  # For each occurrence, extract a 21 word long string with the search term in the middle\n",
    "  extracted_strings = []\n",
    "  for match in matches:\n",
    "    start_index = match.start()\n",
    "    end_index = match.end()\n",
    "\n",
    "    # Split the transcript into words\n",
    "    words_before = transcript[:start_index].split()\n",
    "    words_after = transcript[end_index:].split()\n",
    "    if len(words_before) < 10:\n",
    "      return\n",
    "    if len(words_after) < 10:\n",
    "      return\n",
    "\n",
    "\n",
    "    # Extract the 21 word long string\n",
    "    string = ' '.join(words_before[-10:] + [search_term] + words_after[:10])\n",
    "    extracted_strings.append(string)\n",
    "\n",
    "  return extracted_strings\n",
    "\n",
    "\n",
    "# Create an empty list to store the rows of the new DataFrame\n",
    "rows = []\n",
    "\n",
    "# Iterate over the rows of the original DataFrame\n",
    "for _, row in df.iterrows():\n",
    "  medium = row['medium']\n",
    "  id = row['id']\n",
    "  title = row['title']\n",
    "  minute = row['minute']\n",
    "  transcript = row['transcript']\n",
    "\n",
    "\n",
    "  # For each search term, extract the relevant strings and add a row to the new DataFrame for each occurrence\n",
    "  for term in search_terms.keys():\n",
    "    extracted_strings = extract_string(transcript, term)\n",
    "    if extracted_strings:\n",
    "      for extracted_string in extracted_strings:\n",
    "        rows.append({'medium': medium, 'id': id, 'title': title, 'minute': minute, 'search_term': term, 'extracted_string': extracted_string})\n",
    "\n",
    "# Create the new DataFrame from the list of rows\n",
    "party_df = pd.DataFrame(rows, columns=['medium', 'id', 'title', 'minute', 'search_term', 'extracted_string'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_df['party'] = party_df['search_term'].apply(lambda x: search_terms[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spd                            28808\n",
       "cdu                            28157\n",
       "fdp                            19041\n",
       "csu                            10641\n",
       "die grünen                     10225\n",
       "afg                             7003\n",
       "afd                             3920\n",
       "die linke                       3072\n",
       "linkspartei                     1817\n",
       "freien demokraten                335\n",
       "alternative für deutschland      135\n",
       "Name: search_term, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "party_df.search_term.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_df.to_pickle('../data/mentions/party_mentions.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the rows of the new DataFrame\n",
    "rows = []\n",
    "\n",
    "# Iterate over the rows of the original DataFrame\n",
    "for _, row in df.iterrows():\n",
    "  medium = row['medium']\n",
    "  id = row['id']\n",
    "  title = row['title']\n",
    "  minute = row['minute']\n",
    "  transcript = row['transcript']\n",
    "\n",
    "\n",
    "  # For each search term, extract the relevant strings and add a row to the new DataFrame for each occurrence\n",
    "  for politician in politicians.keys():\n",
    "    extracted_strings = extract_string(transcript, politician)\n",
    "    if extracted_strings:\n",
    "      for extracted_string in extracted_strings:\n",
    "        rows.append({'medium': medium, 'id': id, 'title': title, 'minute': minute, 'search_term': politician, 'extracted_string': extracted_string})\n",
    "\n",
    "# Create the new DataFrame from the list of rows\n",
    "politician_df = pd.DataFrame(rows, columns=['medium', 'id', 'title', 'minute',  'search_term', 'extracted_string'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "politician_df['party'] = politician_df['search_term'].apply(lambda x: politicians[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "olaf scholz          13114\n",
       "armin laschet         7175\n",
       "friedrich merz        4250\n",
       "annalena baerbock     4040\n",
       "karl lauterbach       3197\n",
       "                     ...  \n",
       "ralph edelhäußer         1\n",
       "leon eckert              1\n",
       "jan dieren               1\n",
       "anna christmann          1\n",
       "heike brehmer            1\n",
       "Name: search_term, Length: 477, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politician_df.search_term.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politician_df.to_pickle('../data/mentions/politician_mentions.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mention_count = politician_df.groupby(['search_term', 'medium', 'id', 'title']).size()\n",
    "mention_count = mention_count.reset_index(name='mention_count')\n",
    "unique_politician_df = mention_count.drop(columns=['id', 'title']).groupby(['medium', 'search_term']).count().sort_values('mention_count', ascending=False).reset_index()\n",
    "unique_politician_df['party'] = unique_politician_df['search_term'].apply(lambda x: politicians[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medium</th>\n",
       "      <th>search_term</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WELT</td>\n",
       "      <td>olaf scholz</td>\n",
       "      <td>1057</td>\n",
       "      <td>spd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BILD</td>\n",
       "      <td>olaf scholz</td>\n",
       "      <td>766</td>\n",
       "      <td>spd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WELT</td>\n",
       "      <td>armin laschet</td>\n",
       "      <td>634</td>\n",
       "      <td>cdu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZDF</td>\n",
       "      <td>olaf scholz</td>\n",
       "      <td>569</td>\n",
       "      <td>spd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BILD</td>\n",
       "      <td>armin laschet</td>\n",
       "      <td>485</td>\n",
       "      <td>cdu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>ZDF</td>\n",
       "      <td>frank ullrich</td>\n",
       "      <td>1</td>\n",
       "      <td>spd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>ZDF</td>\n",
       "      <td>franziska brantner</td>\n",
       "      <td>1</td>\n",
       "      <td>grüne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>DER SPIEGEL</td>\n",
       "      <td>ingrid nestle</td>\n",
       "      <td>1</td>\n",
       "      <td>grüne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>DER SPIEGEL</td>\n",
       "      <td>harald ebner</td>\n",
       "      <td>1</td>\n",
       "      <td>grüne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>WELT</td>\n",
       "      <td>ingmar jung</td>\n",
       "      <td>1</td>\n",
       "      <td>cdu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1572 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           medium         search_term  mention_count  party\n",
       "0            WELT         olaf scholz           1057    spd\n",
       "1            BILD         olaf scholz            766    spd\n",
       "2            WELT       armin laschet            634    cdu\n",
       "3             ZDF         olaf scholz            569    spd\n",
       "4            BILD       armin laschet            485    cdu\n",
       "...           ...                 ...            ...    ...\n",
       "1567          ZDF       frank ullrich              1    spd\n",
       "1568          ZDF  franziska brantner              1  grüne\n",
       "1569  DER SPIEGEL       ingrid nestle              1  grüne\n",
       "1570  DER SPIEGEL        harald ebner              1  grüne\n",
       "1571         WELT         ingmar jung              1    cdu\n",
       "\n",
       "[1572 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_politician_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_politician_df.to_pickle('../data/mentions/politician_mentions_unique.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ae7ae13804f56b6812076ff88d4c743516b7c995d69dd5984882be015e04ad2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
